from typing import Dict, Any, List, Optional
from dataclasses import dataclass
import logging
from pathlib import Path
from statistics import mean
import json
import time
from clearml import Task, Logger
from omegaconf import OmegaConf
try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

from ..models.base import BaseModel
from ..retrievers.base import BaseRetriever
from ..data.base import BaseDataset, DatasetItem
from .metrics import TokenRecallCalculator
from ..utils.memory_tracker import MemoryTracker
from ..utils.predictions_tracker import PredictionsTracker
from ..utils.logger_wrapper import LoggerWrapper
from ..utils.local_logger import LocalLogger
from ..utils.clearml_config import (
    setup_clearml_environment, 
    create_clearml_task, 
    get_clearml_logger,
    log_experiment_config,
    log_predictions_to_clearml,
    log_metrics_to_clearml
)

@dataclass
class ExperimentConfig:
    """Configuration for an experiment run."""
    name: str
    model_config: Dict[str, Any]
    retriever_config: Dict[str, Any]
    dataset_config: Dict[str, Any]
    metrics_config: Dict[str, Any]
    output_dir: Path
    max_samples: Optional[int] = None
    use_retriever: bool = False
    context_type: str = "none"
    prompt_template: str = "Question: {question}\nAnswer:"  # default prompt
    model: Optional[Any] = None

class ExperimentRunner:
    """Main class for running experiments."""
    
    def __init__(self, config: ExperimentConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º metric_calculator –ø–æ–∑–∂–µ, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–∞
        # —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ tokenizer, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å
        self.metric_calculator = None
        self.memory_tracker = MemoryTracker(Path(config.output_dir))
        self.predictions_tracker = PredictionsTracker(Path(config.output_dir))
        
    def setup_experiment(self, use_clearml: bool = True):
        """Initialize ClearML, create directories, etc."""
        self.use_clearml = use_clearml  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Ç–æ–¥–∞—Ö
        if use_clearml:
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º ClearML —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º .env —Ñ–∞–π–ª–∞
            setup_clearml_environment()
            
            # –°–æ–∑–¥–∞–µ–º ClearML –∑–∞–¥–∞—á—É
            self.task = create_clearml_task(
                project_name="slm-experiments",
                task_name=self.config.name,
                tags=[self.config.model_config.get('name', 'unknown'), 
                      self.config.dataset_config.get('name', 'unknown'),
                      self.config.context_type]
            )
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º output_uri –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –≤ MinIO S3
            # –ü—Ä–æ–±—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —è–≤–Ω–æ, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º default_output_uri
            s3_output_uri = f"s3://clearml-artifacts/{self.config.name}"
            try:
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º output_uri –¥–ª—è –∑–∞–¥–∞—á–∏
                # –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã upload_artifact() —Å–æ—Ö—Ä–∞–Ω—è–ª –≤ S3, –∞ –Ω–µ –≤ fileserver
                self.task.output_uri = s3_output_uri
                self.logger.info(f"üì¶ Output URI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: {s3_output_uri}")
                self.logger.info(f"üíæ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤ MinIO bucket 'clearml-artifacts'")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ output_uri –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
                actual_output_uri = getattr(self.task, 'output_uri', None)
                if actual_output_uri:
                    self.logger.info(f"‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ: output_uri = {actual_output_uri}")
                else:
                    self.logger.warning("‚ö†Ô∏è  output_uri –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏")
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å output_uri, –∏—Å–ø–æ–ª—å–∑—É–µ–º default_output_uri –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
                self.logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å output_uri: {e}")
                self.logger.info("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è default_output_uri –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                self.logger.info("‚ö†Ô∏è –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –º–æ–≥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å—Å—è –≤ fileserver –≤–º–µ—Å—Ç–æ MinIO")
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º OmegaConf –æ–±—ä–µ–∫—Ç—ã –≤ –æ–±—ã—á–Ω—ã–µ Python —Ç–∏–ø—ã –¥–ª—è ClearML
            config_dict = {
                "model": self.config.model_config,
                "retriever": self.config.retriever_config,
                "dataset": self.config.dataset_config,
                "metrics": self.config.metrics_config,
                "experiment": {
                    "name": self.config.name,
                    "max_samples": self.config.max_samples,
                    "use_retriever": self.config.use_retriever,
                    "context_type": self.config.context_type
                },
                "prompt": {
                    "template": self.config.prompt_template
                }
            }
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤–µ—Å—å —Å–ª–æ–≤–∞—Ä—å —Ü–µ–ª–∏–∫–æ–º
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å (–µ—Å–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã —É–∂–µ dict, —Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º)
            try:
                config_plain = OmegaConf.to_container(config_dict, resolve=True)
            except (ValueError, TypeError):
                # –ï—Å–ª–∏ config_dict —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ã—á–Ω—ã–µ dict, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
                config_plain = config_dict
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
            self.task.connect(config_plain)
            
            # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            clearml_logger = get_clearml_logger()
            self.logger = LoggerWrapper(clearml_logger)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            full_config = {
                "model": self.config.model_config,
                "retriever": self.config.retriever_config,
                "dataset": self.config.dataset_config,
                "metrics": self.config.metrics_config,
                "experiment": {
                    "name": self.config.name,
                    "output_dir": str(self.config.output_dir),
                    "max_samples": self.config.max_samples,
                    "use_retriever": self.config.use_retriever,
                    "context_type": self.config.context_type
                },
                "prompt": {
                    "template": self.config.prompt_template
                }
            }
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –æ–±—ã—á–Ω—ã–µ Python —Ç–∏–ø—ã
            try:
                full_config_plain = OmegaConf.to_container(full_config, resolve=True)
            except (ValueError, TypeError):
                # –ï—Å–ª–∏ full_config —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ã—á–Ω—ã–µ dict, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
                full_config_plain = full_config
            log_experiment_config(self.logger, full_config_plain)
        else:
            # –†–µ–∂–∏–º –±–µ–∑ ClearML - –∏—Å–ø–æ–ª—å–∑—É–µ–º LocalLogger
            self.task = None
            self.local_logger = LocalLogger(self.config.output_dir)
            python_logger = logging.getLogger(__name__)
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º LocalLogger –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π logger —á–µ—Ä–µ–∑ wrapper
            self.logger = LoggerWrapper(self.local_logger)
            self.logger.info("üöÄ –ù–∞—á–∞–ª–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (–±–µ–∑ ClearML)")
            self.logger.info(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {self.config.output_dir}")
            self.logger.info(f"ü§ñ –ú–æ–¥–µ–ª—å: {self.config.model_config.get('name', 'unknown')}")
            self.logger.info(f"üìä –î–∞—Ç–∞—Å–µ—Ç: {self.config.dataset_config.get('name', 'unknown')}")
            self.logger.info(f"üîç –†–µ–∂–∏–º: {self.config.context_type}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
            full_config = {
                "model": self.config.model_config,
                "retriever": self.config.retriever_config,
                "dataset": self.config.dataset_config,
                "metrics": self.config.metrics_config,
                "experiment": {
                    "name": self.config.name,
                    "output_dir": str(self.config.output_dir),
                    "max_samples": self.config.max_samples,
                    "use_retriever": self.config.use_retriever,
                    "context_type": self.config.context_type
                },
                "prompt": {
                    "template": self.config.prompt_template
                }
            }
            try:
                full_config_plain = OmegaConf.to_container(full_config, resolve=True)
            except (ValueError, TypeError):
                full_config_plain = full_config
            self.local_logger.config = full_config_plain
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.config.output_dir.mkdir(parents=True, exist_ok=True)
        
    def run(self, model: BaseModel, retriever: BaseRetriever, dataset: BaseDataset, use_clearml: bool = True):
        """Run the experiment."""
        self.setup_experiment(use_clearml=use_clearml)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º metric_calculator —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º –º–æ–¥–µ–ª–∏
        # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–¥—Å—á–µ—Ç–∞ recall - –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ—Ç –∂–µ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
        if hasattr(model, 'tokenizer') and model.tokenizer is not None:
            self.metric_calculator = TokenRecallCalculator(tokenizer=model.tokenizer)
            self.logger.info("‚úÖ TokenRecallCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–æ–º –º–æ–¥–µ–ª–∏")
        else:
            # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –º–æ–¥–µ–ª–∏
            model_path = self.config.model_config.get('model_path', 'bert-base-uncased')
            self.metric_calculator = TokenRecallCalculator(tokenizer_name=model_path)
            self.logger.warning(f"‚ö†Ô∏è  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞: {model_path}")
        
        # Initial memory state
        self.memory_tracker.log_memory("system", "experiment_start")
        
        # Log prompt template from config
        if hasattr(self.logger, 'report_text'):
            self.logger.report_text("üìù –®–∞–±–ª–æ–Ω –ø—Ä–æ–º–ø—Ç–∞:")
            self.logger.report_text("")
            self.logger.report_text("```")
            self.logger.report_text(self.config.prompt_template)
            self.logger.report_text("```")
        else:
            self.logger.info(f"Prompt template: {self.config.prompt_template}")
        
        # Log basic info as single values (–Ω–µ —Å–æ–∑–¥–∞—é—Ç –≥—Ä–∞—Ñ–∏–∫–∏)
        if hasattr(self.logger, 'report_single_value'):
            self.logger.report_single_value("model_size_bytes", model.get_model_size())
            if retriever is not None:
                self.logger.report_single_value("retriever_index_size", retriever.get_index_size())
            # Log dataset stats
            for key, value in dataset.get_dataset_stats().items():
                self.logger.report_single_value(f"dataset_{key}", value)
        else:
            # Fallback –¥–ª—è —Ä–µ–∂–∏–º–∞ –±–µ–∑ ClearML
            self.logger.info(f"Model size: {model.get_model_size()}")
            if retriever is not None:
                self.logger.info(f"Retriever index size: {retriever.get_index_size()}")
            for key, value in dataset.get_dataset_stats().items():
                self.logger.info(f"Dataset {key}: {value}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
        self.logger.report_text("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏...")
        start_time = time.time()
        
        metrics = self._evaluate(model, retriever, dataset)
        
        end_time = time.time()
        duration = end_time - start_time
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if hasattr(self.logger, 'report_single_value'):
            self.logger.report_single_value("duration_seconds", duration)
        self.logger.report_text(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏ –∏ —Ä–∞–∑–º–µ—Ä–∞—Ö –≤ –º–µ—Ç—Ä–∏–∫–∏
        metrics['duration_seconds'] = duration
        metrics['model_size_bytes'] = model.get_model_size()
        metrics['model_size_mb'] = model.get_model_size() / (1024 * 1024)
        
        if retriever is not None:
            metrics['retriever_index_size_bytes'] = retriever.get_index_size()
            metrics['retriever_index_size_mb'] = retriever.get_index_size() / (1024 * 1024)
        else:
            metrics['retriever_index_size_bytes'] = 0
            metrics['retriever_index_size_mb'] = 0
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_results(metrics)
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–æ–≥–∞
        self.memory_tracker.log_memory("system", "experiment_end")
        self.memory_tracker.save_log()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∏–∫–æ–≤–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏ –≤ –º–µ—Ç—Ä–∏–∫–∏
        if self.memory_tracker.peak_stats:
            peak_memory = self.memory_tracker.peak_stats.to_dict()
            metrics.update(peak_memory)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø–∏–∫–æ–≤—É—é –ø–∞–º—è—Ç—å –∏ –º–æ—â–Ω–æ—Å—Ç—å
            self.logger.report_text("üíæ –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏:")
            self.logger.report_text(f"  CPU RAM: {peak_memory['cpu_ram_used_mb']:.2f} MB")
            if peak_memory['gpu_ram_peak_mb'] > 0:
                self.logger.report_text(f"  GPU RAM (peak): {peak_memory['gpu_ram_peak_mb']:.2f} MB")
                self.logger.report_text(f"  GPU RAM (reserved): {peak_memory['reserved_gpu_ram_mb']:.2f} MB")
            if peak_memory.get('gpu_power_draw_w', 0) > 0:
                power_limit = peak_memory.get('gpu_power_limit_w', 0)
                power_pct = (peak_memory['gpu_power_draw_w'] / power_limit * 100) if power_limit > 0 else 0
                self.logger.report_text(f"  GPU Power (peak): {peak_memory['gpu_power_draw_w']:.2f}W / {power_limit:.2f}W ({power_pct:.1f}%)")
        
        # –ü–µ—Ä–µ—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        self._save_results(metrics)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ MinIO
        # –ü–µ—Ä–µ–¥–∞–µ–º callback –¥–ª—è –ø—Ä—è–º–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –≤ MinIO —á–µ—Ä–µ–∑ Docker —Å–µ—Ç—å
        if self.use_clearml and self.task is not None:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤ MinIO —á–µ—Ä–µ–∑ callback
            predictions_s3_path = self.predictions_tracker.save_predictions(
                upload_to_minio_callback=self._upload_to_minio_direct
            )
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ ClearML —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ —Å—Å—ã–ª–∫–æ–π –Ω–∞ MinIO
            if predictions_s3_path:
                predictions_file = self.config.output_dir / "predictions.json"
                self._register_clearml_artifact(
                    name="model_predictions",
                    s3_path=predictions_s3_path,
                    local_file=predictions_file,
                    metadata={
                        "experiment_name": self.config.name,
                        "num_predictions": len(self.predictions_tracker.predictions),
                        "timestamp": time.time(),
                        "storage": "MinIO S3",
                        "s3_path": predictions_s3_path
                    }
                )
        else:
            self.predictions_tracker.save_predictions()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        self.logger.report_text("‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        self.logger.report_text(f"üìà –¢–æ–∫–µ–Ω-—Ä–µ–∫–æ–ª–ª: {metrics.get('token_recall', 0):.4f}")
        self.logger.report_text(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {metrics.get('num_examples', 0)}")
        self.logger.report_text(f"üì¶ –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏: {metrics.get('model_size_mb', 0):.2f} MB")
        self.logger.report_text(f"üîç –†–∞–∑–º–µ—Ä –∏–Ω–¥–µ–∫—Å–∞ RAG: {metrics.get('retriever_index_size_mb', 0):.2f} MB")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
        if not self.use_clearml and hasattr(self, 'local_logger'):
            self.local_logger.save_all(self.config.name)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
            results_file = self.config.output_dir / "results.json"
            if results_file.exists():
                self.local_logger.save_artifact("experiment_results", results_file)
            
            predictions_file = self.config.output_dir / "predictions.json"
            if predictions_file.exists():
                self.local_logger.save_artifact("model_predictions", predictions_file)
            
            memory_file = self.config.output_dir / "memory_usage.json"
            if memory_file.exists():
                self.local_logger.save_artifact("memory_usage", memory_file)
        
    def _get_context(self, item: DatasetItem, retriever: Optional[BaseRetriever]) -> List[str]:
        """Get context based on experiment mode."""
        if not self.config.use_retriever:
            if self.config.context_type == "none":
                return []
            elif self.config.context_type == "oracle":
                return [item.context] if item.context else []
        else:
            if not retriever:
                raise ValueError("Retriever is required for retriever_context mode")
            contexts = retriever.retrieve(
                item.question, 
                top_k=self.config.top_k
            )
            return [c.context for c in contexts if c.score >= self.config.min_score]

    def _evaluate(self, model: BaseModel, retriever: Optional[BaseRetriever], 
                 dataset: BaseDataset) -> Dict[str, float]:
        """Evaluate model performance using token recall metric."""
        recalls = []
        processed = 0
        logged_prompt_examples = 0  # Track how many prompt examples we've logged
        max_prompt_examples = 20  # Log first 20 prompt examples
        
        # Get total number of examples for progress tracking
        eval_data = list(dataset.get_eval_data())
        total_examples = len(eval_data)
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –æ—Ç–≤–µ—Ç–∞–º–∏ (–¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞)
        valid_examples = sum(1 for item in eval_data if item.answer)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        max_to_process = valid_examples
        if self.config.max_samples:
            max_to_process = min(valid_examples, self.config.max_samples)
        
        self.logger.info(f"üìä –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {max_to_process} (–∏–∑ {total_examples} –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        if HAS_TQDM:
            pbar = tqdm(
                total=max_to_process,
                desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–º–µ—Ä–æ–≤",
                unit="–ø—Ä–∏–º–µ—Ä",
                ncols=100,
                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
            )
        else:
            pbar = None
        
        for item in eval_data:
            if not item.answer:  # Skip items without ground truth
                continue
            
            if self.config.max_samples and processed >= self.config.max_samples:
                break
                
            # Track memory for retrieval
            if retriever:
                self.memory_tracker.log_memory("retriever", "before_retrieve")
            
            # Get context based on experiment mode
            contexts = self._get_context(item, retriever)
            
            if retriever:
                self.memory_tracker.log_memory("retriever", "after_retrieve")
            
            # Track memory for model inference
            self.memory_tracker.log_memory("model", "before_generate")
            
            # Generate answer
            predicted_answer = model.generate(
                prompt=item.question,
                context=contexts,
                prompt_template=self.config.prompt_template
            )
            
            # Log prompt examples for first few items
            if logged_prompt_examples < max_prompt_examples and hasattr(model, 'last_prompt'):
                if hasattr(self.logger, 'report_text'):
                    self.logger.report_text(f"\nüí¨ –ü—Ä–∏–º–µ—Ä –ø—Ä–æ–º–ø—Ç–∞ #{logged_prompt_examples + 1}:")
                    self.logger.report_text("```")
                    self.logger.report_text(model.last_prompt)
                    self.logger.report_text("```")
                    self.logger.report_text(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {predicted_answer}")
                    self.logger.report_text(f"–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: {item.answer}")
                logged_prompt_examples += 1
            
            self.memory_tracker.log_memory("model", "after_generate")
            
            # Calculate token recall
            recall = self.metric_calculator.calculate_recall(
                predicted=predicted_answer,
                ground_truth=item.answer
            )
            recalls.append(recall)
            
            # Track prediction
            self.predictions_tracker.add_prediction(
                question_id=item.metadata.get('id', str(processed)),
                question=item.question,
                predicted_answer=predicted_answer,
                ground_truth=item.answer,
                contexts=contexts,
                context_type=self.config.context_type,
                model_name=self.config.model_config.get('name', 'unknown'),
                token_recall=recall,
                metadata={
                    'dataset': self.config.dataset_config.get('name', 'unknown'),
                    **item.metadata
                },
                prompt=model.last_prompt if hasattr(model, 'last_prompt') else None
            )
            
            # Log individual example progress (—Å–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞)
            if hasattr(self.logger, 'report_scalar'):
                self.logger.report_scalar(
                    title="Training Progress",
                    series="token_recall",
                    value=recall,
                    iteration=processed
                )
            
            # Increment processed counter
            processed += 1
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
            if pbar:
                pbar.update(1)
                pbar.set_postfix({
                    'recall': f'{mean(recalls)*100:.2f}%' if recalls else '0%',
                    'processed': processed
                })
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ª–æ–≥ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏
            log_interval = 10  # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 –ø—Ä–∏–º–µ—Ä–æ–≤
            if processed % log_interval == 0 or processed == 1:
                avg_recall = mean(recalls) if recalls else 0.0
                progress_pct = (processed / max_to_process * 100) if max_to_process > 0 else 0
                self.logger.info(
                    f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {processed}/{max_to_process} ({progress_pct:.1f}%) | "
                    f"–°—Ä–µ–¥–Ω–∏–π recall: {avg_recall*100:.2f}% | "
                    f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}"
                )
            
            # Clear memory periodically and log progress AFTER incrementing
            if processed % 100 == 0:
                self.memory_tracker.clear_memory()
                avg_recall = mean(recalls) if recalls else 0.0
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ 100 –ø—Ä–∏–º–µ—Ä–æ–≤ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–∞–º—è—Ç–∏ –∏ –º–æ—â–Ω–æ—Å—Ç–∏
                memory_stats = self.memory_tracker.get_current_memory_usage()
                gpu_info = f"GPU RAM: {memory_stats.gpu_ram_used:.1f} MB" if memory_stats.gpu_ram_used else "GPU RAM: N/A"
                power_info = ""
                if memory_stats.gpu_power_draw is not None:
                    power_pct = (memory_stats.gpu_power_draw / memory_stats.gpu_power_limit * 100) if memory_stats.gpu_power_limit else 0
                    power_info = f" | GPU Power: {memory_stats.gpu_power_draw:.1f}W/{memory_stats.gpu_power_limit:.1f}W ({power_pct:.1f}%)"
                self.logger.info(
                    f"üíæ –ü–∞–º—è—Ç—å: CPU RAM: {memory_stats.cpu_ram_used:.1f} MB | {gpu_info}{power_info}"
                )
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
        if pbar:
            pbar.close()
        
        # Calculate average recall
        avg_recall = mean(recalls) if recalls else 0.0
        
        return {
            "token_recall": avg_recall,
            "num_examples": len(recalls)
        }
    
    def _save_results(self, metrics: Dict[str, float]):
        """Save experiment results to disk and upload to ClearML."""
        results_file = self.config.output_dir / "results.json"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ª–æ–∫–∞–ª—å–Ω–æ
        with open(results_file, "w") as f:
            json.dump(metrics, f, indent=2)
        
        if self.task is not None:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–ø—Ä—è–º—É—é –≤ MinIO
            self.logger.info("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ MinIO...")
            s3_path = self._upload_to_minio_direct(results_file, "experiment_results/results.json")
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ ClearML —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ —Å—Å—ã–ª–∫–æ–π –Ω–∞ MinIO
            if s3_path:
                self._register_clearml_artifact(
                    name="experiment_results",
                    s3_path=s3_path,
                    local_file=results_file,
                    metadata={
                        "experiment_name": self.config.name,
                        "model": self.config.model_config.get('name', 'unknown'),
                        "dataset": self.config.dataset_config.get('name', 'unknown'),
                        "retriever": self.config.retriever_config.get('name', 'unknown'),
                        "timestamp": time.time(),
                        "storage": "MinIO S3",
                        "s3_path": s3_path
                    }
                )
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ MinIO —á–µ—Ä–µ–∑ save_predictions() —Å callback
            # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –ø—Ä–æ–∏–∑–æ–π–¥–µ—Ç –ø–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ save_predictions()
            
            # –¢–∞–∫–∂–µ –∑–∞–≥—Ä—É–∂–∞–µ–º memory usage –≤ MinIO –µ—Å–ª–∏ –µ—Å—Ç—å
            memory_file = self.config.output_dir / "memory_usage.json"
            if memory_file.exists():
                self.logger.info("üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –ø–∞–º—è—Ç–∏ –≤ MinIO...")
                s3_path = self._upload_to_minio_direct(memory_file, "experiment_results/memory_usage.json")
                
                # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ ClearML —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ —Å—Å—ã–ª–∫–æ–π –Ω–∞ MinIO
                if s3_path:
                    self._register_clearml_artifact(
                        name="memory_usage",
                        s3_path=s3_path,
                        local_file=memory_file,
                        metadata={
                            "experiment_name": self.config.name,
                            "timestamp": time.time(),
                            "storage": "MinIO S3",
                            "s3_path": s3_path
                        }
                    )
            
            # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞
            cleanup_local = self.config.model_config.get('cleanup_local_artifacts', False)
            if cleanup_local:
                self.logger.info("üóëÔ∏è  –û—á–∏—Å—Ç–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3...")
                import os
                try:
                    if results_file.exists():
                        os.remove(results_file)
                    if predictions_file.exists():
                        os.remove(predictions_file)
                    if memory_file.exists():
                        os.remove(memory_file)
                    self.logger.info("‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —É–¥–∞–ª–µ–Ω—ã (—Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ S3)")
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã: {e}")
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ ClearML
            if hasattr(self.predictions_tracker, 'predictions') and self.predictions_tracker.predictions:
                log_predictions_to_clearml(self.logger, self.predictions_tracker.predictions)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ ClearML
            log_metrics_to_clearml(self.logger, metrics)
        else:
            # –†–µ–∂–∏–º –±–µ–∑ ClearML - –ª–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ –ª–æ–∫–∞–ª—å–Ω—ã–π –ª–æ–≥–≥–µ—Ä
            if hasattr(self, 'local_logger'):
                # –õ–æ–≥–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–∫ single values
                for metric_name, value in metrics.items():
                    self.local_logger.report_single_value(metric_name, value)
                
                # –¢–∞–∫–∂–µ –ª–æ–≥–∏—Ä—É–µ–º –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º –≤–∏–¥–µ
                self.logger.info("üìä –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞:")
                for metric_name, value in metrics.items():
                    self.logger.info(f"  {metric_name}: {value:.4f}")
    
    def _upload_to_minio_direct(self, file_path: Path, s3_key: str) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é –≤ MinIO —á–µ—Ä–µ–∑ boto3.
        
        Returns:
            S3 path –≤ —Ñ–æ—Ä–º–∞—Ç–µ s3://bucket/key –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            import boto3
            from dotenv import load_dotenv
            import os
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env (–µ—Å–ª–∏ —Ñ–∞–π–ª –¥–æ—Å—Ç—É–ø–µ–Ω)
            # –í Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ .env –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
            load_dotenv()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º endpoint: –≤ Docker —Å–µ—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞, –∏–Ω–∞—á–µ localhost
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è > –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ Docker —Å–µ—Ç–∏ > localhost
            endpoint = os.getenv('CLEARML_S3_ENDPOINT')
            if endpoint:
                self.logger.info(f"üîç –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è endpoint –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è: {endpoint}")
            else:
                # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω minio:9000, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                try:
                    import socket
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å minio —á–µ—Ä–µ–∑ Docker —Å–µ—Ç—å
                    socket.gethostbyname('minio')
                    endpoint = 'http://minio:9000'
                    self.logger.info(f"üîç –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Docker —Å–µ—Ç—å endpoint: {endpoint}")
                except (socket.gaierror, OSError):
                    # –ï—Å–ª–∏ minio –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º localhost
                    endpoint = 'http://localhost:9000'
                    self.logger.info(f"üîç –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è localhost endpoint: {endpoint}")
                    self.logger.warning("‚ö†Ô∏è  MinIO —á–µ—Ä–µ–∑ Docker —Å–µ—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è localhost. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω –≤ —Å–µ—Ç–∏ clearml_backend")
            
            # –°–æ–∑–¥–∞–µ–º S3 –∫–ª–∏–µ–Ω—Ç –¥–ª—è MinIO
            access_key = os.getenv('CLEARML_S3_ACCESS_KEY', 'minioadmin')
            secret_key = os.getenv('CLEARML_S3_SECRET_KEY', 'minioadmin')
            bucket = os.getenv('CLEARML_S3_BUCKET', 'clearml-artifacts')
            
            self.logger.info(f"üîß –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MinIO: endpoint={endpoint}, bucket={bucket}")
            
            s3_client = boto3.client(
                's3',
                endpoint_url=endpoint,
                aws_access_key_id=access_key,
                aws_secret_access_key=secret_key,
                region_name=os.getenv('CLEARML_S3_REGION', 'us-east-1')
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å MinIO –∏ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ bucket
            try:
                # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ bucket'–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                s3_client.list_buckets()
                self.logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ MinIO —É—Å–ø–µ—à–Ω–æ")
            except Exception as conn_error:
                self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MinIO: {conn_error}")
                self.logger.error(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ MinIO –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É {endpoint}")
                self.logger.error(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω –≤ Docker —Å–µ—Ç–∏ clearml_backend")
                return None
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ bucket, —Å–æ–∑–¥–∞–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            try:
                s3_client.head_bucket(Bucket=bucket)
                self.logger.info(f"‚úÖ Bucket '{bucket}' —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            except Exception as e:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–¥ –æ—à–∏–±–∫–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –ø—Ä–æ–±–ª–µ–º—ã
                error_code = None
                if hasattr(e, 'response') and isinstance(e.response, dict):
                    error_code = e.response.get('Error', {}).get('Code', '')
                elif hasattr(e, 'error_code'):
                    error_code = e.error_code
                
                # 404 –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ bucket –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
                if error_code == '404' or '404' in str(e) or 'Not Found' in str(e):
                    # Bucket –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, —Å–æ–∑–¥–∞–µ–º –µ–≥–æ
                    self.logger.info(f"üì¶ Bucket '{bucket}' –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º...")
                    try:
                        s3_client.create_bucket(Bucket=bucket)
                        self.logger.info(f"‚úÖ Bucket '{bucket}' —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω")
                    except Exception as create_error:
                        self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å bucket '{bucket}': {create_error}")
                        return None
                else:
                    # –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–æ—Å—Ç—É–ø–æ–º)
                    self.logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å bucket '{bucket}': {e}")
                    self.logger.info(f"üí° –ü—Ä–æ–±—É–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å - bucket –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ")
            
            full_s3_key = f"{self.config.name}/{s3_key}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            if not file_path.exists():
                self.logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
                return None
            
            file_size = file_path.stat().st_size
            self.logger.info(f"üì§ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ {file_path} ({file_size} bytes) -> s3://{bucket}/{full_s3_key}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            s3_client.upload_file(
                str(file_path),
                bucket,
                full_s3_key
            )
            
            s3_path = f"s3://{bucket}/{full_s3_key}"
            self.logger.info(f"‚úÖ –§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ MinIO: {s3_path}")
            return s3_path
            
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –≤ MinIO –Ω–∞–ø—Ä—è–º—É—é: {e}")
            import traceback
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ MinIO
            self.logger.warning("‚ö†Ô∏è  –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ MinIO")
            return None
    
    def _register_clearml_artifact(self, name: str, s3_path: str, local_file: Path, metadata: Dict[str, Any]):
        """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ ClearML —Å –ø—Ä—è–º—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º S3 –ø—É—Ç–∏ –≤ MinIO.
        
        –ü—Ä–æ–±—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å S3 URI –Ω–∞–ø—Ä—è–º—É—é. –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª-—Å—Å—ã–ª–∫—É
        —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ –≤ MinIO –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
        """
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ –≤ MinIO –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata_with_s3 = metadata.copy()
            metadata_with_s3["s3_path"] = s3_path
            metadata_with_s3["storage_location"] = "MinIO S3"
            metadata_with_s3["storage_url"] = s3_path  # –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ MinIO
            metadata_with_s3["note"] = f"–§–∞–π–ª —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ MinIO –ø–æ –ø—É—Ç–∏: {s3_path}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º output_uri –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
            current_output_uri = getattr(self.task, 'output_uri', None)
            if current_output_uri:
                self.logger.info(f"üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è output_uri: {current_output_uri}")
            else:
                self.logger.warning("‚ö†Ô∏è  output_uri –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –ê—Ä—Ç–µ—Ñ–∞–∫—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω –≤ fileserver")
            
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å S3 –ø—É—Ç—å –Ω–∞–ø—Ä—è–º—É—é
            # ClearML –º–æ–∂–µ—Ç –ø–æ–Ω–∏–º–∞—Ç—å S3 URI –µ—Å–ª–∏ output_uri –Ω–∞—Å—Ç—Ä–æ–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
            try:
                self.task.upload_artifact(
                    name=name,
                    artifact_object=s3_path,  # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å S3 –ø—É—Ç—å –Ω–∞–ø—Ä—è–º—É—é
                    metadata=metadata_with_s3
                )
                self.logger.info(f"‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç '{name}' –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ ClearML —Å S3 –ø—É—Ç–µ–º: {s3_path}")
                return
            except Exception as s3_error:
                # –ï—Å–ª–∏ –ø—Ä—è–º–æ–π S3 –ø—É—Ç—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —Å–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª-—Å—Å—ã–ª–∫—É
                self.logger.debug(f"–ü—Ä—è–º–æ–π S3 –ø—É—Ç—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {s3_error}")
                self.logger.info(f"üí° –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª-—Å—Å—ã–ª–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ MinIO")
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª-—Å—Å—ã–ª–∫—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ –≤ MinIO
            import json as json_lib
            link_file = local_file.parent / f"{name}_minio_link.json"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º bucket –∏ key –∏–∑ s3_path
            # –§–æ—Ä–º–∞—Ç: s3://bucket/key
            s3_parts = s3_path.replace("s3://", "").split("/", 1)
            bucket = s3_parts[0] if len(s3_parts) > 0 else "clearml-artifacts"
            key = s3_parts[1] if len(s3_parts) > 1 else ""
            
            # –ü–æ–ª—É—á–∞–µ–º MinIO endpoint –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
            import os
            minio_endpoint = os.getenv('CLEARML_S3_ENDPOINT', 'http://minio:9000')
            # –£–±–∏—Ä–∞–µ–º http:// –∏–ª–∏ https:// –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Å—ã–ª–∫–∏
            minio_host = minio_endpoint.replace("http://", "").replace("https://", "")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ MinIO (–¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ boto3 –∏–ª–∏ curl)
            minio_direct_url = f"{minio_endpoint}/{bucket}/{key}"
            
            link_info = {
                "artifact_name": name,
                "storage": "MinIO S3",
                "s3_path": s3_path,
                "bucket": bucket,
                "key": key,
                "minio_endpoint": minio_endpoint,
                "minio_host": minio_host,
                "direct_access_url": minio_direct_url,
                "access_method": "Use boto3 or S3 client with endpoint_url",
                "endpoint_url": minio_endpoint,
                "bucket_name": bucket,
                "object_key": key,
                "credentials": {
                    "access_key": os.getenv('CLEARML_S3_ACCESS_KEY', 'minioadmin'),
                    "secret_key": os.getenv('CLEARML_S3_SECRET_KEY', 'minioadmin')
                },
                "note": "–≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –≤ MinIO. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ s3_path –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ —á–µ—Ä–µ–∑ boto3 –∏–ª–∏ S3-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π –∫–ª–∏–µ–Ω—Ç.",
                "metadata": metadata_with_s3
            }
            
            with open(link_file, 'w', encoding='utf-8') as f:
                json_lib.dump(link_info, f, indent=2, ensure_ascii=False)
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª-—Å—Å—ã–ª–∫—É –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç
            # –í –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —É–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ MinIO
            metadata_with_s3["minio_direct_url"] = minio_direct_url
            metadata_with_s3["minio_access_info"] = {
                "endpoint": minio_endpoint,
                "bucket": bucket,
                "key": key,
                "s3_path": s3_path
            }
            
            self.task.upload_artifact(
                name=name,
                artifact_object=str(link_file),
                metadata=metadata_with_s3
            )
            
            self.logger.info(f"‚úÖ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç '{name}' –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω –≤ ClearML")
            self.logger.info(f"üì¶ –§–∞–π–ª –≤ MinIO: {s3_path}")
            self.logger.info(f"üîó –ü—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ MinIO: {minio_direct_url}")
            self.logger.info(f"üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É –≤ MinIO")
            
        except Exception as e:
            self.logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ç–µ—Ñ–∞–∫—Ç –≤ ClearML: {e}")
            import traceback
            self.logger.debug(f"Traceback: {traceback.format_exc()}")
            # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, —Ñ–∞–π–ª —É–∂–µ –≤ MinIO
