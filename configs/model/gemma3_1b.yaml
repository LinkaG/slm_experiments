name: gemma3_1b
model_type: huggingface
model_size: 1B
model_path: google/gemma-3-1b-it
max_length: 512
temperature: 0.2  # Низкая температура для фактологических ответов (меньше "сочинительства")
top_p: 0.95  # Более консервативный top_p
repetition_penalty: 1.1  # Умеренный штраф за повторения
max_new_tokens: 50  # Короткие конкретные ответы для фактологических вопросов
device: cuda
use_flash_attention: false  # flash_attn not installed
# Token для доступа к gated модели берется из переменной окружения HF_TOKEN

