# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—é –ø–∞–º—è—Ç–∏

## üìä **–ö–∞–∫—É—é –ø–∞–º—è—Ç—å –º—ã –∏–∑–º–µ—Ä—è–µ–º?**

### **1. CPU RAM (–û–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å)**

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è:**
```python
cpu_ram_used_mb = process.memory_info().rss / (1024 * 1024)
```

**RSS (Resident Set Size)** - —ç—Ç–æ:
- ‚úÖ –§–∏–∑–∏—á–µ—Å–∫–∞—è –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º Python
- ‚úÖ –í–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
  - –î–∞—Ç–∞—Å–µ—Ç –≤ –ø–∞–º—è—Ç–∏
  - –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –Ω–∞ CPU)
  - –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è
  - –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ Python
  - –ö—ç—à –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞

**–ù–ï –≤–∫–ª—é—á–∞–µ—Ç:**
- ‚ùå Swap –ø–∞–º—è—Ç—å (–ø–æ–¥–∫–∞—á–∫–∞ –Ω–∞ –¥–∏—Å–∫)
- ‚ùå Shared memory –º–µ–∂–¥—É –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏
- ‚ùå GPU –ø–∞–º—è—Ç—å

---

### **2. GPU RAM (–í–∏–¥–µ–æ–ø–∞–º—è—Ç—å)**

#### **a) `gpu_ram_used_mb` - –í—ã–¥–µ–ª–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å**
```python
gpu_ram_used = torch.cuda.memory_allocated() / (1024 * 1024)
```

**–ß—Ç–æ —ç—Ç–æ:**
- ‚úÖ –ü–∞–º—è—Ç—å, **—Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è** PyTorch –¥–ª—è —Ç–µ–Ω–∑–æ—Ä–æ–≤
- ‚úÖ –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ GPU
- ‚úÖ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
- ‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)

**–ü—Ä–∏–º–µ—Ä:**
```
–ú–æ–¥–µ–ª—å 1.7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ √ó 4 –±–∞–π—Ç–∞ (float32) = ~6.8 GB
+ –ê–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –∫—ç—à KV = –µ—â–µ ~2-4 GB
–ò—Ç–æ–≥–æ: ~10 GB —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
```

---

#### **b) `gpu_ram_peak_mb` - –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ**
```python
gpu_ram_peak = torch.cuda.max_memory_allocated() / (1024 * 1024)
```

**–ß—Ç–æ —ç—Ç–æ:**
- ‚úÖ **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è** –ø–∞–º—è—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ –≤—ã–¥–µ–ª–µ–Ω–∞ –∑–∞ –≤—Å–µ –≤—Ä–µ–º—è
- ‚úÖ –ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ GPU

**–ü—Ä–∏–º–µ—Ä:**
```
–û–±—ã—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: 8 GB
–í–æ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: 12 GB ‚Üê —ç—Ç–æ –∏ –±—É–¥–µ—Ç peak
```

---

#### **c) `reserved_gpu_ram_mb` - –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–∞–º—è—Ç—å**
```python
reserved_gpu_ram = torch.cuda.memory_reserved() / (1024 * 1024)
```

**–ß—Ç–æ —ç—Ç–æ:**
- ‚úÖ –ü–∞–º—è—Ç—å, **–∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω–∞—è** PyTorch —É GPU
- ‚úÖ –ú–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ, —á–µ–º —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
- ‚úÖ PyTorch –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞–º—è—Ç—å GPU —Å—Ä–∞–∑—É (–¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)

**–ü—Ä–∏–º–µ—Ä:**
```
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è: 8 GB
–ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: 10 GB ‚Üê PyTorch –¥–µ—Ä–∂–∏—Ç +2 GB "–ø—Ä–æ –∑–∞–ø–∞—Å"
```

**–ó–∞—á–µ–º PyTorch —Ä–µ–∑–µ—Ä–≤–∏—Ä—É–µ—Ç –±–æ–ª—å—à–µ?**
- –ß—Ç–æ–±—ã –Ω–µ –≤—ã–¥–µ–ª—è—Ç—å/–æ—Å–≤–æ–±–æ–∂–¥–∞—Ç—å –ø–∞–º—è—Ç—å –∫–∞–∂–¥—ã–π —Ä–∞–∑
- –£—Å–∫–æ—Ä—è–µ—Ç –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
- –ú–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å: `torch.cuda.empty_cache()`

---

## üìà **–ö–æ–≥–¥–∞ –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –ø–∞–º—è—Ç—å?**

–°–º–æ—Ç—Ä–∏–º –≤ –∫–æ–¥–µ:

```python
# 1. –í –Ω–∞—á–∞–ª–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
self.memory_tracker.log_memory("system", "experiment_start")

# 2. –ü–µ—Ä–µ–¥/–ø–æ—Å–ª–µ —Ä–µ—Ç—Ä–∏–≤–µ—Ä–∞ (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
self.memory_tracker.log_memory("retriever", "before_retrieve")
# ... retriever.retrieve() ...
self.memory_tracker.log_memory("retriever", "after_retrieve")

# 3. –ü–µ—Ä–µ–¥/–ø–æ—Å–ª–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
self.memory_tracker.log_memory("model", "before_generate")
# ... model.generate() ...
self.memory_tracker.log_memory("model", "after_generate")

# 4. –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –∫–∞–∂–¥—ã–µ 100 –ø—Ä–∏–º–µ—Ä–æ–≤
if processed % 100 == 0:
    self.memory_tracker.clear_memory()  # –û—á–∏—â–∞–µ–º –∫—ç—à

# 5. –í –∫–æ–Ω—Ü–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
self.memory_tracker.log_memory("system", "experiment_end")
self.memory_tracker.save_log()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
```

---

## üíæ **–ì–¥–µ –Ω–∞–π—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã?**

### **1. –õ–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª:**
```bash
outputs/<experiment_name>/memory_usage.json
```

**–§–æ—Ä–º–∞—Ç:**
```json
{
  "detailed_log": [
    {
      "component": "model",
      "operation": "before_generate",
      "timestamp": 1234567890.123,
      "cpu_ram_used_mb": 1024.5,
      "gpu_ram_used_mb": 8192.3,
      "gpu_ram_peak_mb": 8500.1,
      "reserved_gpu_ram_mb": 10240.0
    },
    ...
  ],
  "peak_usage": {
    "cpu_ram_used_mb": 1200.0,
    "gpu_ram_used_mb": 10240.0,
    "gpu_ram_peak_mb": 12000.0,
    "reserved_gpu_ram_mb": 14000.0
  }
}
```

---

### **2. ClearML Web UI:**

**SCALARS ‚Üí memory/**
```
memory/model/
  ‚îú‚îÄ cpu_ram_used_mb
  ‚îú‚îÄ gpu_ram_used_mb
  ‚îú‚îÄ gpu_ram_peak_mb
  ‚îî‚îÄ reserved_gpu_ram_mb

memory/retriever/
  ‚îú‚îÄ cpu_ram_used_mb
  ‚îî‚îÄ ...

memory/system/
  ‚îú‚îÄ cpu_ram_used_mb
  ‚îî‚îÄ ...
```

**–ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç:**
- X-axis = iteration (–∫–∞–∂–¥–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ)
- Y-axis = –ø–∞–º—è—Ç—å –≤ MB
- –ú–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å –¥–∏–Ω–∞–º–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

---

### **3. MinIO S3:**
```
s3://clearml-artifacts/.../artifacts/memory_usage/memory_usage.json
```

---

## üéØ **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã:**

### **–ü—Ä–∏–º–µ—Ä 1: SmolLM-1.7B –Ω–∞ GPU**
```json
{
  "peak_usage": {
    "cpu_ram_used_mb": 2048,      // ~2 GB CPU (–¥–∞—Ç–∞—Å–µ—Ç + –∫–æ–¥)
    "gpu_ram_used_mb": 8192,       // ~8 GB GPU (–º–æ–¥–µ–ª—å + –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
    "gpu_ram_peak_mb": 10240,      // –ü–∏–∫ ~10 GB
    "reserved_gpu_ram_mb": 12288   // PyTorch –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–ª ~12 GB
  }
}
```

**–í—ã–≤–æ–¥:**
- ‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ GPU
- ‚úÖ –ù—É–∂–Ω–∞ GPU —Å –º–∏–Ω–∏–º—É–º 12 GB –ø–∞–º—è—Ç–∏
- ‚úÖ CPU –∏—Å–ø–æ–ª—å–∑—É–µ—Ç ~2 GB –¥–ª—è –¥–∞–Ω–Ω—ã—Ö

---

### **–ü—Ä–∏–º–µ—Ä 2: –ú–æ–¥–µ–ª—å –Ω–∞ CPU (–Ω–µ—Ç GPU)**
```json
{
  "peak_usage": {
    "cpu_ram_used_mb": 15360,     // ~15 GB CPU (–º–æ–¥–µ–ª—å + –¥–∞–Ω–Ω—ã–µ)
    "gpu_ram_used_mb": 0,          // GPU –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    "gpu_ram_peak_mb": 0,
    "reserved_gpu_ram_mb": 0
  }
}
```

**–í—ã–≤–æ–¥:**
- ‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ CPU
- ‚úÖ –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 16 GB RAM
- ‚ö†Ô∏è  –ë—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –º–µ–¥–ª–µ–Ω–Ω–æ

---

### **–ü—Ä–∏–º–µ—Ä 3: –° –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π (int8)**
```json
{
  "peak_usage": {
    "cpu_ram_used_mb": 2048,
    "gpu_ram_used_mb": 4096,       // –ú–µ–Ω—å—à–µ! 8-bit –≤–º–µ—Å—Ç–æ 32-bit
    "gpu_ram_peak_mb": 5120,       // –ü–∏–∫ —Ç–æ–∂–µ –º–µ–Ω—å—à–µ
    "reserved_gpu_ram_mb": 6144    // –ú–æ–∂–Ω–æ –Ω–∞ –º–µ–Ω—å—à–µ–π GPU!
  }
}
```

**–í—ã–≤–æ–¥:**
- ‚úÖ –ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è —É–º–µ–Ω—å—à–∏–ª–∞ –ø–∞–º—è—Ç—å –≤ ~2 —Ä–∞–∑–∞
- ‚úÖ –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU —Å 8 GB –≤–º–µ—Å—Ç–æ 12 GB

---

## üîç **–ö–∞–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞–º—è—Ç—å?**

### **1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
import json

with open('outputs/.../memory_usage.json') as f:
    data = json.load(f)
    peak = data['peak_usage']
    
    print(f"Peak GPU: {peak['gpu_ram_peak_mb']} MB")
    print(f"Peak CPU: {peak['cpu_ram_used_mb']} MB")
```

### **2. –ù–∞–π—Ç–∏ —É—Ç–µ—á–∫–∏ –ø–∞–º—è—Ç–∏:**
–°–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫ –≤ ClearML:
- –ï—Å–ª–∏ –ø–∞–º—è—Ç—å —Ä–∞—Å—Ç–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω–æ ‚Üí —É—Ç–µ—á–∫–∞
- –ï—Å–ª–∏ –ø–∞–º—è—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–∞ ‚Üí –≤—Å—ë –û–ö

### **3. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å:**
–ï—Å–ª–∏ –ø–∞–º—è—Ç–∏ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç:
- ‚úÖ –£–º–µ–Ω—å—à–∏—Ç—å `batch_size`
- ‚úÖ –í–∫–ª—é—á–∏—Ç—å `gradient_checkpointing`
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—é (`load_in_8bit`)
- ‚úÖ –û—á–∏—â–∞—Ç—å –∫—ç—à: `torch.cuda.empty_cache()`

---

## üìä **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π:**

| –ú–æ–¥–µ–ª—å | Precision | CPU RAM | GPU RAM | GPU Peak | –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π |
|--------|-----------|---------|---------|----------|-------------|
| SmolLM-135M | FP32 | 1 GB | 2 GB | 2.5 GB | –õ–µ–≥–∫–∞—è –º–æ–¥–µ–ª—å |
| SmolLM-1.7B | FP32 | 2 GB | 8 GB | 10 GB | –°—Ä–µ–¥–Ω—è—è –º–æ–¥–µ–ª—å |
| SmolLM-1.7B | INT8 | 2 GB | 4 GB | 5 GB | –° –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π |
| Qwen-4B | FP32 | 3 GB | 18 GB | 22 GB | –ë–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å |
| Qwen-4B | INT8 | 3 GB | 9 GB | 11 GB | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è |

---

## ‚úÖ **–ò—Ç–æ–≥–æ:**

### **–ú—ã –∏–∑–º–µ—Ä—è–µ–º:**
1. **CPU RAM** - –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –ø–∞–º—è—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–∞ (–¥–∞—Ç–∞—Å–µ—Ç + –∫–æ–¥)
2. **GPU RAM Used** - —Ä–µ–∞–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –≤–∏–¥–µ–æ–ø–∞–º—è—Ç—å (–º–æ–¥–µ–ª—å + –∞–∫—Ç–∏–≤–∞—Ü–∏–∏)
3. **GPU RAM Peak** - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (–¥–ª—è –æ—Ü–µ–Ω–∫–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π)
4. **GPU RAM Reserved** - –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–Ω–∞—è PyTorch (–º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ)

### **–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è:**
- ‚úÖ –õ–æ–∫–∞–ª—å–Ω–æ: `outputs/.../memory_usage.json`
- ‚úÖ ClearML: –≥—Ä–∞—Ñ–∏–∫–∏ –≤ SCALARS ‚Üí memory/
- ‚úÖ MinIO S3: –∞—Ä—Ç–µ—Ñ–∞–∫—Ç `memory_usage`

### **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥–ª—è:**
- üéØ –û—Ü–µ–Ω–∫–∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –∫ –∂–µ–ª–µ–∑—É
- üéØ –ü–æ–∏—Å–∫–∞ —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
- üéØ –°—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
- üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤

